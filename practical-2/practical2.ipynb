{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step0: dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step1: load data\n",
    "output:  \n",
    "**input_texts**: list of 2085 talk transcriptions (entire text, not tokenized, mixed case, punctuation etc.)  \n",
    "**labels**: corresponding list of 2085 strings containing several keywords each  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract both the texts and the labels from the xml file\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "texts = doc.xpath('//content/text()')\n",
    "labels = doc.xpath('//head/keywords/text()')\n",
    "del doc\n",
    "#print(input_texts[0])\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step2: preprocessing inputs and labels and building embeddings\n",
    "output:  \n",
    "**inputs_train**: list of 1585 tuples of (token_list, label_integer) for training  \n",
    "**inputs_test**: list of 250 tuples of (token_list, label_integer) for testing  \n",
    "**inputs_cv**: list of 250 tuples of (token_list, label_integer) for cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the texts: lowercase, remove text in parentheses, remove punctuation, tokenize into words (split on whitespace)\n",
    "#removing text in parentheses\n",
    "input_texts = [re.sub(r'\\([^)]*\\)', '', input_text) for input_text in texts]\n",
    "#lowercase\n",
    "input_texts = [input_text.lower() for input_text in input_texts]\n",
    "#remove punctuation\n",
    "input_texts = [re.sub(r'[^a-z0-9]+', ' ', input_text) for input_text in input_texts]\n",
    "#tokenize into words\n",
    "input_texts = [input_text.split() for input_text in input_texts]\n",
    "len(input_texts)\n",
    "#input_texts[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.    671.5  1343.   2014.5  2686.   3357.5  4029.   4700.5  5372.\n",
      "  6043.5  6715. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f708ba62b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram over input lengths\n",
    "Y_plot, X_plot = np.histogram([len(text) for text in input_texts], bins=10)\n",
    "print(X_plot)\n",
    "X_plot = np.arange(10)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4474850 tokens in the dataset.\n",
      "There are 18438 tokens that appear only once.\n",
      "There are 18538 unique tokens to remove.\n",
      "It took 0.5074748992919922 seconds to remove all unnecessary items.\n",
      "There are now only 1926086 tokens in the dataset.\n"
     ]
    }
   ],
   "source": [
    "#get list of all words, and feed them into a Counter\n",
    "all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are {} tokens in the dataset.\".format(len(all_words)))\n",
    "all_words_counter = collections.Counter(all_words)\n",
    "\n",
    "#remove some noise, take away the 100 most common and all words that only appear once\n",
    "most_common_50 = [word for word, count in all_words_counter.most_common(100)]\n",
    "only_once = [word for word, count in all_words_counter.most_common() if count == 1]\n",
    "print(\"There are {} tokens that appear only once.\".format(len(only_once)))\n",
    "\n",
    "to_remove = set(only_once + most_common_50)\n",
    "print(\"There are {} unique tokens to remove.\".format(len(to_remove)))\n",
    "\n",
    "start = time.time()\n",
    "input_texts = [[word for word in input_text if word not in to_remove] for input_text in input_texts]\n",
    "print(\"It took {} seconds to remove all unnecessary items.\".format(time.time()-start))\n",
    "\n",
    "new_all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are now only {} tokens in the dataset.\".format(len(new_all_words)))\n",
    "\n",
    "#input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now only 1924 inputs left.\n"
     ]
    }
   ],
   "source": [
    "#remove all inputs that have less than 500 tokens in them\n",
    "inputs = zip(input_texts, labels)\n",
    "inputs = [text_and_labels for text_and_labels in inputs if len(text_and_labels[0]) > 300]\n",
    "print(\"There are now only {} inputs left.\".format(len(inputs)))\n",
    "input_texts, labels = zip(*inputs)\n",
    "input_texts, labels = list(input_texts), list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#padding every text to the max text length for later batching\n",
    "#l_max = max([len(text) for text in input_texts])\n",
    "#for text in input_texts:\n",
    "#    text += ['<zero_pad>'] * (l_max - len(text))\n",
    "\n",
    "#truncating every text to only the first 500 tokens\n",
    "l_max = 1000\n",
    "input_texts = [text[:l_max] for text in input_texts]\n",
    "input_texts = [(['<zero_pad>'] * (l_max - len(text)) + text) for text in input_texts]\n",
    "\n",
    "#print(input_texts[0][-10:-1])\n",
    "#print(np.mean([len(text) for text in input_texts]) == l_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 5, 0, 0, 0, 0, 5, 0, 3, 2, 5, 0, 0, 3, 0, 5, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the labels: search for occurences of the keywords \"technology\", \"entertainment\" or \"design\" and build labels\n",
    "label_lookup = ['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']\n",
    "for i in range(len(labels)):\n",
    "    ted_labels = ['o', 'o', 'o']\n",
    "    keyword_list = labels[i].split(', ')\n",
    "    if 'technology' in keyword_list:\n",
    "        ted_labels[0] = 'T'\n",
    "    if 'entertainment' in keyword_list:\n",
    "        ted_labels[1] = 'E'\n",
    "    if 'design' in keyword_list:\n",
    "        ted_labels[2] = 'D'\n",
    "    labels[i] = ''.join(ted_labels)\n",
    "    labels[i] = label_lookup.index(labels[i])\n",
    "len(labels)\n",
    "labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35562"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the unique vocabulary lookup\n",
    "vocab_list = list(set([word for input_text in input_texts for word in input_text]))\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "for i, word in enumerate(vocab_list):\n",
    "    word_to_index[word] = i\n",
    "    index_to_word[i] = word\n",
    "input_indices_list = []\n",
    "for input_text in input_texts:\n",
    "    input_indices_list.append([word_to_index[word] for word in input_text])\n",
    "len(vocab_list)\n",
    "#del vocab_list\n",
    "#del input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load glove word vectors\n",
    "glove = KeyedVectors.load_word2vec_format('glove.6B.50d.w2vformat.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 35562 words\n",
      "found 34558 word vectors, 0.9717676171193971 of our vocabulary\n",
      "missing words e.g. ['sneakerheads', 'sammich', 'sanghamitra', 'sristi', 'delish', 'parabiosis', 'whitopians', 'daasanach', 'lmao', 'microbloggers', 'tulles', 'tananger', 'synecdochically', 'diastrophic', 'fortingall', 'manhouse', 'rcif', 'umvelt', 'thylacines', 'unpicking', 'bollacker', 'guaym', 'eetwidomayloh', 'blackawton', 'manspace', 'transfigure', 'angrigami', 'emeruwa', 'hololens', 'otherizing', 'mengatoue', 'cloudbook', 'nkali', 'sitopia', 'compassionating', 'genspace', 'spatialized', 'protonmail', 'computerish', 'zoobiquity', 'brck', 'pffff', 'commodifies', 'malem', 'diybio', 'flagelliform', 'schr', 'resorbing', 'permissionless', 'okollet']\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings, checking for each word in the input texts whether it is part of \n",
    "#the glove corpus, if yes intialize that row in the embeddings with the glove value, if\n",
    "#not initialize it uniformly between [-.1, .1]\n",
    "voc_len = len(word_to_index)\n",
    "print(\"vocabulary size: {} words\".format(voc_len))\n",
    "counter = 0\n",
    "not_found_list = []\n",
    "embeddings = np.random.uniform(-.1, .1, size=(voc_len, 50))\n",
    "for word, index in word_to_index.items():\n",
    "    if word in glove.vocab:\n",
    "        counter += 1\n",
    "        embeddings[index] = glove[word]\n",
    "    elif word == '<zero_pad>':\n",
    "        embeddings[index] = np.zeros(50)\n",
    "    else:\n",
    "        not_found_list.append(word)\n",
    "print(\"found {} word vectors, {} of our vocabulary\".format(counter, float(counter)/voc_len))\n",
    "print(\"missing words e.g. {}\".format(not_found_list[0:50]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1540, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "# combining the tokens and labels for each input, then shuffle them and split into train/test/cv\n",
    "#inputs_combined = list(zip(input_indices_list, labels))\n",
    "#shuffle(inputs_combined)\n",
    "#inputs_train = inputs_combined[:1450]\n",
    "#inputs_test = inputs_combined[1450:1550]\n",
    "#inputs_cv = inputs_combined[1550:]\n",
    "#print((len(inputs_train), len(inputs_test), len(inputs_cv)))\n",
    "#print(inputs_train[0])\n",
    "#print([index_to_word[i] for i in inputs_train[0][0]])\n",
    "#print([input_pair[1] for input_pair in inputs_train])\n",
    "\n",
    "#keep the class label distribution intact\n",
    "inputs_combined = list(zip(input_indices_list, labels))\n",
    "inputs_train, inputs_test, inputs_cv = [], [], []\n",
    "for n in range(len(label_lookup)):\n",
    "    inputs_of_curr_class = [inpu for inpu in inputs_combined if inpu[1] == n]\n",
    "    l = len(inputs_of_curr_class)\n",
    "    split1 = round(0.8*l)\n",
    "    split2 = round(0.9*l)\n",
    "    inputs_train.extend(inputs_of_curr_class[:split1])\n",
    "    inputs_cv.extend(inputs_of_curr_class[split1:split2])\n",
    "    inputs_test.extend(inputs_of_curr_class[split2:])\n",
    "\n",
    "shuffle(inputs_train)\n",
    "shuffle(inputs_cv)\n",
    "shuffle(inputs_test)\n",
    "print((len(inputs_train), len(inputs_test), len(inputs_cv)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgplAEhSoQwASSqUASBJhfr/A7ZsB+7fdssAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f706b50f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a histogram over the label distribution in the entire dataset\n",
    "#as you can see 'ooo' is basically ~50% of the dataset, so an accuracy score\n",
    "#of 50% could be reached by simply learning to predict 'ooo' all the time (not good)\n",
    "Y_plot = np.histogram(labels, bins=8)[0]\n",
    "X_plot = np.arange(8)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')\n",
    "for x,y in zip(X_plot,Y_plot):\n",
    "    plt.text(x, y+0.05, label_lookup[x], ha='center', va= 'bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step3: building the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# building the tensorflow logistic regression model\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TextClassifier(object):\n",
    "    def __init__(self, lr, activation, train_algo, embeddings, train_embeddings, voc_len, embed_size, batch_size, hidden_units, classes):\n",
    "        #placeholders\n",
    "        #(batch_size left)\n",
    "        self.input_ph = tf.placeholder(tf.int32, shape=(None, None), name='input')\n",
    "        self.labels_ph = tf.placeholder(tf.int32, shape=(None, classes), name='labels')\n",
    "        self.dropout_ph = tf.placeholder(tf.float32, shape=(), name='dropout')  \n",
    "        \n",
    "        #embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            #depending on whether a pre-trained embedding is provided and whether or not\n",
    "            #the embedding should be trainable\n",
    "            if embeddings is not None and train_embeddings is True:\n",
    "                self.L = tf.Variable(embeddings, name=\"L\")\n",
    "            elif embeddings is not None and train_embeddings is False:\n",
    "                self.L = tf.constant(embeddings, name=\"L\")\n",
    "            else:\n",
    "                self.L = tf.Variable(tf.random_uniform([voc_len, embed_size], -1.0, 1.0), name=\"L\")\n",
    "            input_vectors = tf.nn.embedding_lookup(self.L, self.input_ph)\n",
    "            X = tf.squeeze(tf.reduce_mean(input_vectors, axis=1, keep_dims=True), axis=1)\n",
    "        \n",
    "        #network model\n",
    "        with tf.name_scope(\"network\"):\n",
    "            W1 = tf.Variable(tf.random_normal((embed_size, hidden_units), stddev=0.1), name=\"W1\")\n",
    "            b1 = tf.Variable(tf.zeros(hidden_units), name='b1')\n",
    "\n",
    "            self.W2 = tf.Variable(tf.random_normal((hidden_units, classes), stddev=0.1), name=\"W2\")\n",
    "            b2 = tf.Variable(tf.zeros(classes), name='b2')\n",
    "            \n",
    "            if activation == 'relu':\n",
    "                hidden = tf.nn.relu(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            elif activation == 'tanh':\n",
    "                hidden = tf.nn.tanh(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            else:\n",
    "                hidden = tf.nn.sigmoid(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            hidden = tf.nn.dropout(hidden, self.dropout_ph)\n",
    "\n",
    "            output = tf.matmul(hidden, self.W2) + b2\n",
    "            output = tf.nn.dropout(output, self.dropout_ph)\n",
    "            #yhat = tf.nn.softmax(out) #no need to calc whole prob dist if we only want the argmax\n",
    "            self.predictions = tf.argmax(output, axis=1)\n",
    "        \n",
    "        #loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.losses = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=self.labels_ph)\n",
    "            l2_loss = tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(self.W2) + tf.nn.l2_loss(b2)\n",
    "            self.loss = tf.reduce_mean(self.losses) + (0.01 * l2_loss)\n",
    "            \n",
    "        #acc\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.labels_ph, axis=1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "            \n",
    "        #training operation\n",
    "        with tf.name_scope(\"training\"):\n",
    "            if train_algo == 'adam':\n",
    "                self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)\n",
    "            elif train_algo == 'adagrad':\n",
    "                self.train_op = tf.train.AdagradOptimizer(lr).minimize(self.loss)\n",
    "            else:\n",
    "                self.train_op = tf.train.GradientDescentOptimizer(lr).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, nn, train_data, cv_data, test_data, batch_size, train_dropout, epochs):\n",
    "        self.nn = nn\n",
    "        self.train_data = train_data\n",
    "        self.cv_data = cv_data\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dropout = train_dropout\n",
    "        self.epochs = epochs\n",
    "        self.W2, self.collect_preds, self.collect_truth = None, [], []\n",
    "\n",
    "    def _get_data_batch(self, curr_index, batch_size, data):\n",
    "        curr_batch = data[curr_index:curr_index+batch_size]\n",
    "        input_batch_list, labels_batch_list = zip(*curr_batch) #unzip the list of input pair tuples (text, label)\n",
    "        #print([len(text) for text in input_batch_list])\n",
    "        curr_input_batch = np.array(input_batch_list, dtype=np.int32)\n",
    "        one_hot = np.zeros((len(labels_batch_list), classes))            \n",
    "        one_hot[range(len(labels_batch_list)), labels_batch_list] = 1            \n",
    "        curr_labels_batch = one_hot\n",
    "        return curr_input_batch, curr_labels_batch\n",
    "    \n",
    "    def _print_status(self, i, epoch_loss, epoch_train_acc, epoch_cv_acc):\n",
    "        print (\"epoch: {}, epoch train loss: {:.3f}, epoch train accuracy: {:.3f}, epoch cv accuracy: {:.3f} \".\n",
    "               format(i, np.mean(epoch_loss), np.mean(epoch_train_acc), np.mean(epoch_cv_acc)))#, end=\"\\r\")\n",
    "        \n",
    "    def run_epoch(self, sess, i):\n",
    "        self.W2 = None\n",
    "        epoch_loss, epoch_train_acc, epoch_cv_acc = [], [], []\n",
    "        #run training on the train data\n",
    "        curr_index = 0\n",
    "        while curr_index < len(self.train_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.train_data)\n",
    "            feed_dict={self.nn.dropout_ph:self.train_dropout, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            self.W2, c_loss, c_losses, c_train_acc, _ = sess.run([self.nn.W2, self.nn.loss, self.nn.losses, self.nn.accuracy, self.nn.train_op], feed_dict=feed_dict)\n",
    "            #print(c_losses)\n",
    "            #print(c_loss)\n",
    "            epoch_loss.append(c_loss)\n",
    "            epoch_train_acc.append(c_train_acc)\n",
    "            curr_index += self.batch_size\n",
    "        \n",
    "        #run cross evaluation on the cv data\n",
    "        curr_index = 0\n",
    "        while curr_index < len(self.cv_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.cv_data)\n",
    "            feed_dict={self.nn.dropout_ph:1.0, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            c_cv_acc = sess.run(self.nn.accuracy, feed_dict=feed_dict)\n",
    "            epoch_cv_acc.append(c_cv_acc)\n",
    "            curr_index += self.batch_size\n",
    "        \n",
    "        self._print_status(i, epoch_loss, epoch_train_acc, epoch_cv_acc)\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Starting training for {} epochs.\".format(self.epochs))\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            for i in range(self.epochs):\n",
    "                self.run_epoch(sess, i)\n",
    "            print(\"Done Training.\")\n",
    "            self._test(sess)\n",
    "        \n",
    "    def _test(self, sess):\n",
    "        print(\"Testing the trained model on the test set.\")\n",
    "        #would be better to choose the best model on cv for this instead of simply the one from the last iteration\n",
    "        curr_index = 0\n",
    "        epoch_test_acc = []\n",
    "        while curr_index < len(self.test_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.test_data)\n",
    "            feed_dict={self.nn.dropout_ph:1.0, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            c_test_acc, test_predictions = sess.run([self.nn.accuracy, self.nn.predictions], feed_dict=feed_dict)\n",
    "            epoch_test_acc.append(c_test_acc)\n",
    "            self.collect_preds.extend(test_predictions)\n",
    "            self.collect_truth.extend(np.argmax(curr_labels_batch, axis=1))\n",
    "            curr_index += self.batch_size\n",
    "        print(\"Test set accuracy: {}\".format(np.mean(epoch_test_acc)))\n",
    "        print(\"Done Testing.\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step4: model instantiation, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 20 epochs.\n",
      "epoch: 0, epoch train loss: 1.815, epoch train accuracy: 0.489, epoch cv accuracy: 0.596 \n",
      "epoch: 1, epoch train loss: 1.607, epoch train accuracy: 0.562, epoch cv accuracy: 0.612 \n",
      "epoch: 2, epoch train loss: 1.517, epoch train accuracy: 0.618, epoch cv accuracy: 0.627 \n",
      "epoch: 3, epoch train loss: 1.393, epoch train accuracy: 0.670, epoch cv accuracy: 0.641 \n",
      "epoch: 4, epoch train loss: 1.331, epoch train accuracy: 0.698, epoch cv accuracy: 0.637 \n",
      "epoch: 5, epoch train loss: 1.327, epoch train accuracy: 0.719, epoch cv accuracy: 0.647 \n",
      "epoch: 6, epoch train loss: 1.261, epoch train accuracy: 0.729, epoch cv accuracy: 0.650 \n",
      "epoch: 7, epoch train loss: 1.216, epoch train accuracy: 0.760, epoch cv accuracy: 0.595 \n",
      "epoch: 8, epoch train loss: 1.210, epoch train accuracy: 0.748, epoch cv accuracy: 0.645 \n",
      "epoch: 9, epoch train loss: 1.215, epoch train accuracy: 0.757, epoch cv accuracy: 0.632 \n",
      "epoch: 10, epoch train loss: 1.155, epoch train accuracy: 0.774, epoch cv accuracy: 0.638 \n",
      "epoch: 11, epoch train loss: 1.160, epoch train accuracy: 0.767, epoch cv accuracy: 0.672 \n",
      "epoch: 12, epoch train loss: 1.112, epoch train accuracy: 0.805, epoch cv accuracy: 0.655 \n",
      "epoch: 13, epoch train loss: 1.100, epoch train accuracy: 0.782, epoch cv accuracy: 0.662 \n",
      "epoch: 14, epoch train loss: 1.113, epoch train accuracy: 0.796, epoch cv accuracy: 0.646 \n",
      "epoch: 15, epoch train loss: 1.095, epoch train accuracy: 0.796, epoch cv accuracy: 0.660 \n",
      "epoch: 16, epoch train loss: 1.106, epoch train accuracy: 0.783, epoch cv accuracy: 0.653 \n",
      "epoch: 17, epoch train loss: 1.085, epoch train accuracy: 0.790, epoch cv accuracy: 0.657 \n",
      "epoch: 18, epoch train loss: 1.099, epoch train accuracy: 0.796, epoch cv accuracy: 0.673 \n",
      "epoch: 19, epoch train loss: 1.043, epoch train accuracy: 0.801, epoch cv accuracy: 0.663 \n",
      "Done Training.\n",
      "Testing the trained model on the test set.\n",
      "Test set accuracy: 0.6395238637924194\n",
      "Done Testing.\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "embed_size = 50\n",
    "batch_size = 50\n",
    "hidden_units = 50\n",
    "learning_rate = 0.03\n",
    "voc_len = len(word_to_index)\n",
    "classes = len(label_lookup)\n",
    "\n",
    "\n",
    "#instantiate a network\n",
    "#this can now be tested with all kinds of configurations\n",
    "#'tanh', 'adam', dropout of 0.5 and a lr of 0.05 seems to work best for me\n",
    "nn = TextClassifier(\n",
    "    lr=learning_rate,\n",
    "    activation='tanh',\n",
    "    train_algo='adam',\n",
    "    embeddings=embeddings, #or embeddings=None\n",
    "    train_embeddings=True,\n",
    "    voc_len=voc_len,\n",
    "    embed_size=embed_size,\n",
    "    batch_size=batch_size,\n",
    "    hidden_units=hidden_units,\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "#instantiate a trainer, train the model on the train data and then run the test on the test data\n",
    "trainer = Trainer(\n",
    "    nn=nn,\n",
    "    train_data=inputs_train,\n",
    "    cv_data=inputs_cv,\n",
    "    test_data=inputs_test,\n",
    "    batch_size=batch_size,\n",
    "    train_dropout=0.5,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f704428c320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDnozs8Q56M3MEuegNzNL3P8HA0tefNtXrLAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7048730be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(9)\n",
    "plt.hist(np.array(trainer.collect_preds), bins, alpha=0.5, label='predictions')\n",
    "plt.hist(np.array(trainer.collect_truth), bins, alpha=0.5, label='truth')\n",
    "plt.legend(loc='upper right')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([107,  37,  13,  15,   3,  12,   2,   3]),\n",
       " array([ 0.   ,  0.875,  1.75 ,  2.625,  3.5  ,  4.375,  5.25 ,  6.125,  7.   ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(trainer.collect_truth, bins=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step5: visualizing the hidden to output weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0805548bfe5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumnDataSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "plot_W2 = tsne.fit_transform(trainer.W2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=plot_W2[:,0],\n",
    "                                    x2=plot_W2[:,1],\n",
    "                                    names=label_lookup))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
